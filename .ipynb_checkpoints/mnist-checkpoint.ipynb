{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "272d38e0-d079-418b-870d-4715bbd10f5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b4ba3b9c-72c7-4a5d-944b-3b49a11fe02f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# carregar dados do arquivo CSV\n",
    "df = pd.read_csv('dataset/mnist_train.csv')\n",
    "\n",
    "# extrair coluna de rótulos (labels)\n",
    "y = df['label'].values\n",
    "\n",
    "# extrair colunas de pixels e convertê-los em arrays de imagem\n",
    "x = df.iloc[:, 1:].values.reshape(df.shape[0], 28, 28, 1)\n",
    "\n",
    "# normalizar valores dos pixels para [0,1]\n",
    "x = x.astype('float32')\n",
    "x /= 255\n",
    "\n",
    "# converter rótulos em vetores de classes binárias\n",
    "y = to_categorical(y, 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "12270011-53b0-45f6-9506-22dd1d58e8c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# definir modelo\n",
    "model = Sequential()\n",
    "\n",
    "# primeira camada convolucional com 32 filtros de tamanho 3x3\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "\n",
    "# segunda camada convolucional com 64 filtros de tamanho 3x3\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# camada de max pooling com tamanho de janela 2x2\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "# camada de dropout para evitar overfitting\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "# camada de achatamento para converter a saída em um vetor 1D\n",
    "model.add(Flatten())\n",
    "\n",
    "# camada densa com 128 neurônios e função de ativação ReLU\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "# camada de dropout para evitar overfitting\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# camada de saída com 10 neurônios (1 para cada dígito)\n",
    "# e função de ativação softmax para obter uma distribuição de probabilidade\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# compilar modelo com função de perda categorical cross-entropy,\n",
    "# otimizador Adam e métrica de acurácia\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "28ea6e6b-e734-4424-8484-2ce58d7d8a85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# compilar modelo\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb8a79a3-00f0-4bd0-b5be-ad7b2707ba66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "375/375 [==============================] - 35s 92ms/step - loss: 0.2797 - accuracy: 0.9135 - val_loss: 0.0628 - val_accuracy: 0.9818\n",
      "Epoch 2/10\n",
      "375/375 [==============================] - 39s 103ms/step - loss: 0.0982 - accuracy: 0.9704 - val_loss: 0.0508 - val_accuracy: 0.9855\n",
      "Epoch 3/10\n",
      "375/375 [==============================] - 40s 107ms/step - loss: 0.0723 - accuracy: 0.9773 - val_loss: 0.0395 - val_accuracy: 0.9879\n",
      "Epoch 4/10\n",
      "375/375 [==============================] - 37s 99ms/step - loss: 0.0561 - accuracy: 0.9831 - val_loss: 0.0394 - val_accuracy: 0.9888\n",
      "Epoch 5/10\n",
      "375/375 [==============================] - 38s 102ms/step - loss: 0.0480 - accuracy: 0.9857 - val_loss: 0.0409 - val_accuracy: 0.9890\n",
      "Epoch 6/10\n",
      "375/375 [==============================] - 37s 99ms/step - loss: 0.0403 - accuracy: 0.9871 - val_loss: 0.0393 - val_accuracy: 0.9887\n",
      "Epoch 7/10\n",
      "375/375 [==============================] - 37s 100ms/step - loss: 0.0361 - accuracy: 0.9886 - val_loss: 0.0427 - val_accuracy: 0.9893\n",
      "Epoch 8/10\n",
      "375/375 [==============================] - 38s 101ms/step - loss: 0.0322 - accuracy: 0.9896 - val_loss: 0.0352 - val_accuracy: 0.9915\n",
      "Epoch 9/10\n",
      "375/375 [==============================] - 37s 99ms/step - loss: 0.0308 - accuracy: 0.9900 - val_loss: 0.0374 - val_accuracy: 0.9897\n",
      "Epoch 10/10\n",
      "375/375 [==============================] - 38s 101ms/step - loss: 0.0265 - accuracy: 0.9909 - val_loss: 0.0388 - val_accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# treinar modelo\n",
    "model.fit(x, y,\n",
    "          batch_size=128,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_split=0.2)\n",
    "\n",
    "# salvar modelo treinado\n",
    "model.save('mnist_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f466454a-05f5-48cd-b04e-6f71e1d45a3a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 2s 5ms/step\n",
      "Test accuracy: 0.9907\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# carregar dados de teste do arquivo CSV\n",
    "df_test = pd.read_csv('dataset/mnist_test.csv')\n",
    "\n",
    "# extrair colunas de pixels e remover a primeira coluna de rótulos\n",
    "x_test = df_test.iloc[:, 1:].values\n",
    "\n",
    "# normalizar valores dos pixels para [0,1] e redimensionar para o formato esperado pelo modelo\n",
    "x_test = x_test.astype('float32') / 255\n",
    "x_test = x_test.reshape(-1, 28, 28, 1)\n",
    "\n",
    "# carregar modelo treinado\n",
    "model = load_model('mnist_model.h5')\n",
    "\n",
    "# extrair coluna de rótulos e converter para array numpy\n",
    "y_test = df_test.iloc[:, 0].values\n",
    "\n",
    "# avaliar modelo nos dados de teste\n",
    "y_pred = model.predict(x_test)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# imprimir acurácia\n",
    "acc = np.mean(y_pred == y_test)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "198273cf-20d0-4a34-88f6-26a55a3908cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@7688.511] global loadsave.cpp:244 findDecoder imread_('numeros.jepg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[77], line 47\u001b[0m\n\u001b[1;32m     44\u001b[0m caminho_imagem \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeros.jepg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# Chamar a função para recortar os números da imagem\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m numeros_recortados \u001b[38;5;241m=\u001b[39m \u001b[43mrecortar_numeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcaminho_imagem\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Exibir os números recortados usando matplotlib\u001b[39;00m\n\u001b[1;32m     50\u001b[0m fig \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mfigure()\n",
      "Cell \u001b[0;32mIn[77], line 9\u001b[0m, in \u001b[0;36mrecortar_numeros\u001b[0;34m(imagem)\u001b[0m\n\u001b[1;32m      6\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(imagem)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Converter a imagem para escala de cinza\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m img_gray \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcvtColor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCOLOR_BGR2GRAY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Binarizar a imagem usando um valor de limiar adequado\u001b[39;00m\n\u001b[1;32m     12\u001b[0m _, img_thresh \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mthreshold(img_gray, \u001b[38;5;241m200\u001b[39m, \u001b[38;5;241m255\u001b[39m, cv2\u001b[38;5;241m.\u001b[39mTHRESH_BINARY_INV)\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.7.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def recortar_numeros(imagem):\n",
    "    # Carregar a imagem\n",
    "    img = cv2.imread(imagem)\n",
    "\n",
    "    # Converter a imagem para escala de cinza\n",
    "    img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Binarizar a imagem usando um valor de limiar adequado\n",
    "    _, img_thresh = cv2.threshold(img_gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "    # Encontrar contornos dos objetos na imagem binarizada\n",
    "    contours, _ = cv2.findContours(img_thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Criar uma lista para armazenar as informações dos contornos\n",
    "    contornos = []\n",
    "\n",
    "    # Iterar sobre os contornos encontrados\n",
    "    for contour in contours:\n",
    "        # Obter o retângulo delimitador do contorno\n",
    "        (x, y, w, h) = cv2.boundingRect(contour)\n",
    "\n",
    "        # Adicionar as informações do contorno à lista\n",
    "        contornos.append((x, y, w, h))\n",
    "\n",
    "    # Ordenar os contornos com base na coordenada x\n",
    "    contornos = sorted(contornos, key=lambda c: c[0])\n",
    "\n",
    "    # Criar uma lista para armazenar as imagens recortadas dos números\n",
    "    numeros_recortados = []\n",
    "\n",
    "    # Recortar os números da imagem original na ordem correta\n",
    "    for (x, y, w, h) in contornos:\n",
    "        numero_recortado = img[y:y+h, x:x+w]\n",
    "        numero_redimensionado = cv2.resize(numero_recortado, (28, 28))\n",
    "        numeros_recortados.append(numero_redimensionado)\n",
    "\n",
    "    return numeros_recortados\n",
    "\n",
    "# Caminho da imagem com os números\n",
    "# caminho_imagem = 'numeros_manuscrito.jpg'\n",
    "caminho_imagem = 'numeros.jpeg'\n",
    "\n",
    "# Chamar a função para recortar os números da imagem\n",
    "numeros_recortados = recortar_numeros(caminho_imagem)\n",
    "\n",
    "# Exibir os números recortados usando matplotlib\n",
    "fig = plt.figure()\n",
    "\n",
    "# Preprocessar as imagens recortadas e fazer as previsões com o modelo\n",
    "previsoes = []\n",
    "for numero in numeros_recortados:\n",
    "    numero = cv2.cvtColor(numero, cv2.COLOR_BGR2GRAY)\n",
    "    numero = numero.astype('float32') / 255\n",
    "    numero = np.expand_dims(numero, axis=-1)\n",
    "    numero = np.expand_dims(numero, axis=0)\n",
    "    previsao = model.predict(numero)\n",
    "    previsao = np.argmax(previsao)\n",
    "    previsoes.append(previsao)\n",
    "\n",
    "# Imprimir as previsões\n",
    "print('Previsões:', previsoes)\n",
    "\n",
    "# Exibir as imagens recortadas\n",
    "fig, axs = plt.subplots(1, len(numeros_recortados), figsize=(10, 2))\n",
    "for i, numero in enumerate(numeros_recortados):\n",
    "    axs[i].imshow(cv2.cvtColor(numero, cv2.COLOR_BGR2RGB))\n",
    "    axs[i].set_title('p[i]: {}'.format(previsoes[i]))\n",
    "    axs[i].axis('off')\n",
    "plt.show()\n",
    "\n",
    "# for i, numero_recortado in enumerate(numeros_recortados):\n",
    "#     ax = fig.add_subplot(1, len(numeros_recortados), i+1)\n",
    "#     ax.imshow(cv2.cvtColor(numero_recortado, cv2.COLOR_BGR2RGB))\n",
    "#     ax.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360b519c-8af8-417a-a5c1-7c38e96ec864",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
